{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MASTER_NOTEBOOK.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMD7NhxMvU1Iy1R8yKi5but"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Music Genre Recognition on GTZAN"],"metadata":{"id":"7tnUvP-n1uSj"}},{"cell_type":"code","execution_count":20,"metadata":{"id":"Pp-3Xj151Zxp","executionInfo":{"status":"ok","timestamp":1649562445155,"user_tz":240,"elapsed":306,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"}}},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# !git clone https://github.com/ConcoLab/genrecog.git\n","# %cd genrecog\n","# print(\"The repository is cloned from github\")\n","# !gdown --id 1ZkJwOQPGR_okWNAPbJ8_6YtDOCog5fg3\n","# !gdown --id 1gPI8Jd94jCniZLHC2-KLVHPw0HlfNvFx\n","# !ls\n","# !wget -O train.npz -c \"https://users.encs.concordia.ca/~a_hraf/index.php\" -P \"/dataset/npz_files/\"\n","# !wget -O train.npz -c \"https://users.encs.concordia.ca/~a_hraf/train.npz\" -P /dataset/npz_files/\n","# !wget -O test.npz -c \"https://users.encs.concordia.ca/~a_hraf/test.npz\" -P ./dataset/npz_files/"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"TVfbLLsflHNw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","%cd drive/MyDrive/genrecog/\n","%pip install speechbrain"],"metadata":{"id":"gCJbzWQ81jMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Essntial Libraries\n","from genrecog.preprocess.preprocessor import Preprocessor\n","from genrecog.nnet.CNN import Conv1d, VanillaConv1d, VanillaConv2d\n","from genrecog.nnet.RNN import VanillaRNN, LSTM, GRU\n","from genrecog.tools.trainer import CNNFbankTrainer, RNNFbankTrainer, SklearnTrainer, KmeansTrainer\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader \n","import datetime\n","from genrecog.preprocess.feature import Feature\n","from IPython.display import Audio\n","import matplotlib.pyplot as plt\n","\n","\n","\n","torch.manual_seed(0)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"2KOfVs_Z13qk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_preprcessor = Preprocessor('dataset/npz_files/train.npz')\n","test_preprcessor = Preprocessor('dataset/npz_files/test.npz')\n"],"metadata":{"id":"jNnsXq3p197_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Processed Data\n","The following code shows that we actually using a set of musics which are converted to waves and then we use Fast Fourier Transform (FFT) with using a library available in speechbrain library (FBank) to extract the features."],"metadata":{"id":"ogllQT24JouD"}},{"cell_type":"code","source":["# Load a sample dataset for demonstration purposes\n","X_test, y_test = test_preprcessor.as_shuffled_numpy()"],"metadata":{"id":"IKqhqH7XJXDc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Listen a Part of a Music\n","Each sample in X_test is a music sample that you can listen to and they have a length of 7 seconds."],"metadata":{"id":"mSU4jwjYMmup"}},{"cell_type":"code","source":["Audio(X_test[0], rate=22050)"],"metadata":{"id":"bxTHIo7aKpcG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Also you can see the wave resulting from each sample that is gotten from the music."],"metadata":{"id":"SnL-ibvuM0CX"}},{"cell_type":"code","source":["plt.plot(X_test[0])"],"metadata":{"id":"D6S_3FYiLjve"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, it is the time to extract the features off the sample. So, you can see that each sample is turned to a two-dimensional array containig FFT samples."],"metadata":{"id":"GaEV7O5tM7c-"}},{"cell_type":"code","source":["feature_maker = Feature()\n","print(\"Shape of the music waves:\", X_test.shape)\n","X_test_features = feature_maker.numpy_fbank_features(X_test)\n","print(\"Resulted sample features shape:\", X_test_features.shape)\n"],"metadata":{"id":"HW5ZIQM5MW6U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And finally we can plot the features:"],"metadata":{"id":"aWo5MFR5Nf_w"}},{"cell_type":"code","source":["plt.imshow(X_test_features[0].T, \n","           cmap='viridis', \n","           interpolation='nearest', \n","           aspect='auto', origin='left, bottom')\n","plt.title('Transformed music sample using FBank')\n","plt.ylabel('channel')\n","plt.xlabel('time')"],"metadata":{"id":"c7uwlIx3MHNj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Neural Network Data Preparation\n","\n","To train neural network models, we need to define the DataLoaders. So, we have prepared three different DataLoaders for training, validation and test. This allowed us to reuse the same method for both RNN and CNN at the further steps. \n","\n","**It is important to note that we set the size of batches to 400 and you might need to change it due to RAM constraints.**"],"metadata":{"id":"UwyxT4DOScIr"}},{"cell_type":"code","source":["batch_size = 400 # If your RAM does not support you can replace it with 100\n","\n","X, y = train_preprcessor.as_shuffled_torch()\n","X_test, y_test = test_preprcessor.as_shuffled_torch()\n","\n","dataset = TensorDataset(X.to(device), y.to(device))\n","validation_dataset, train_dataset = torch.utils.data.random_split(dataset, (400, 3200))\n","test_dataset = TensorDataset(X_test.to(device), y_test.to(device))\n","\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","validation_dataloader = DataLoader(validation_dataset, shuffle=True, batch_size=batch_size)\n","test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"kfcRhfGx2AE4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Also, we took 100 as the numnber of epochs in all of the trained models before deciding for overfitting. Here you are able to set it to 100 if you'd like to compare our stated results with this notebook. You would be able to see all the epochs' information after each training process."],"metadata":{"id":"Dvrw1iXUUUNF"}},{"cell_type":"code","source":["num_epochs=10 # You can change it to 100 for closer results"],"metadata":{"id":"Fra99-hUUTJL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Recurrent Neural Network\n","\n","We have decided to train different models on RNN to see which of them works better than the others. So, we fixed the following hyperparameters and change the RNN core functions. The layer that are used include VanillaRNN, LSTM, and GRU. Also, for each of them we used two different variations. One was taking the last hidden layer as the output of the forward function and the other was taking the average of all hidden layers as the output function."],"metadata":{"id":"xKJ8R9O4-VqS"}},{"cell_type":"code","source":["hidden_size = 128\n","num_layers = 5\n","input_size = 40\n","output_dim = 10\n","time_sequence = 702\n","lr = 0.001"],"metadata":{"id":"FyTBMGIl-gms"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.1. VanillaRNN with Using Last Layer of the Hidden Layers"],"metadata":{"id":"cP6KrTFU_LxB"}},{"cell_type":"code","source":["%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss\n","loss = torch.nn.CrossEntropyLoss()\n","model = VanillaRNN(\n","    input_size=input_size, \n","    time_sequence=time_sequence,\n","    hidden_size=hidden_size, \n","    num_layers=num_layers, \n","    output_dim=output_dim,\n","    use_mean=False\n","    ).to(device)\n","loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","print(model)\n","trainer = RNNFbankTrainer(\n","    model=model, \n","    optimizer=optimizer, \n","    loss=loss, \n","    train_dataloader=train_dataloader, \n","    validation_dataloader=validation_dataloader, \n","    num_epochs=num_epochs)\n","trainer.train()\n","trainer.plot_loss(\"training and validation loss\")\n","trainer.plot_accuracies(\"training and validation accuracy\")\n","trainer.plot_confusion_matrix(test_dataloader, 'confusion matrix')\n","y_pred, y_eval, loss, accuracy = trainer.eval(test_dataloader)\n","print(\"accuracy: \", accuracy * 100)"],"metadata":{"id":"iFoBrTAC9pp0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2. VanillaRNN with Using Mean Value of All Hidden Layers"],"metadata":{"id":"pTzDdwxb_Xl5"}},{"cell_type":"code","source":["%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss\n","loss = torch.nn.CrossEntropyLoss()\n","model = VanillaRNN(\n","    input_size=input_size, \n","    time_sequence=time_sequence,\n","    hidden_size=hidden_size, \n","    num_layers=num_layers, \n","    output_dim=output_dim,\n","    use_mean=True\n","    ).to(device)\n","loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","print(model)\n","trainer = RNNFbankTrainer(\n","    model=model, \n","    optimizer=optimizer, \n","    loss=loss, \n","    train_dataloader=train_dataloader, \n","    validation_dataloader=validation_dataloader, \n","    num_epochs=num_epochs)\n","trainer.train()\n","trainer.plot_loss(\"training and validation loss\")\n","trainer.plot_accuracies(\"training and validation accuracy\")\n","trainer.plot_confusion_matrix(test_dataloader, 'confusion matrix')\n","y_pred, y_eval, loss, accuracy = trainer.eval(test_dataloader)\n","print(\"accuracy: \", accuracy * 100)"],"metadata":{"id":"DxK2NwSM_VKD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3. LSTM with Using Last Layer of Hidden Layers"],"metadata":{"id":"2ELBkVqT_zMf"}},{"cell_type":"code","source":["%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss\n","loss = torch.nn.CrossEntropyLoss()\n","model = LSTM(\n","    input_size=input_size, \n","    time_sequence=time_sequence,\n","    hidden_size=hidden_size, \n","    num_layers=num_layers, \n","    output_dim=output_dim,\n","    use_mean=False\n","    ).to(device)\n","loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","print(model)\n","trainer = RNNFbankTrainer(\n","    model=model, \n","    optimizer=optimizer, \n","    loss=loss, \n","    train_dataloader=train_dataloader, \n","    validation_dataloader=validation_dataloader, \n","    num_epochs=num_epochs)\n","trainer.train()\n","trainer.plot_loss(\"training and validation loss\")\n","trainer.plot_accuracies(\"training and validation accuracy\")\n","trainer.plot_confusion_matrix(test_dataloader, 'confusion matrix')\n","y_pred, y_eval, loss, accuracy = trainer.eval(test_dataloader)\n","print(\"accuracy: \", accuracy * 100)"],"metadata":{"id":"JuGYG7B5_zMi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.4. LSTM with Using Mean Value of All Hidden Layers"],"metadata":{"id":"rOo6h9rF_zMm"}},{"cell_type":"code","source":["%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss\n","loss = torch.nn.CrossEntropyLoss()\n","model = LSTM(\n","    input_size=input_size, \n","    time_sequence=time_sequence,\n","    hidden_size=hidden_size, \n","    num_layers=num_layers, \n","    output_dim=output_dim,\n","    use_mean=True\n","    ).to(device)\n","loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","print(model)\n","trainer = RNNFbankTrainer(\n","    model=model, \n","    optimizer=optimizer, \n","    loss=loss, \n","    train_dataloader=train_dataloader, \n","    validation_dataloader=validation_dataloader, \n","    num_epochs=num_epochs)\n","trainer.train()\n","trainer.plot_loss(\"training and validation loss\")\n","trainer.plot_accuracies(\"training and validation accuracy\")\n","trainer.plot_confusion_matrix(test_dataloader, 'confusion matrix')\n","y_pred, y_eval, loss, accuracy = trainer.eval(test_dataloader)\n","print(\"accuracy: \", accuracy * 100)"],"metadata":{"id":"89P4eBxL_zMn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.5. GRU with Using Last Layer of the Hidden Layers"],"metadata":{"id":"x2AqScT6ABHd"}},{"cell_type":"code","source":["%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss\n","loss = torch.nn.CrossEntropyLoss()\n","model = GRU(\n","    input_size=input_size, \n","    time_sequence=time_sequence,\n","    hidden_size=hidden_size, \n","    num_layers=num_layers, \n","    output_dim=output_dim,\n","    use_mean=False\n","    ).to(device)\n","loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","print(model)\n","trainer = RNNFbankTrainer(\n","    model=model, \n","    optimizer=optimizer, \n","    loss=loss, \n","    train_dataloader=train_dataloader, \n","    validation_dataloader=validation_dataloader, \n","    num_epochs=num_epochs)\n","trainer.train()\n","trainer.plot_loss(\"training and validation loss\")\n","trainer.plot_accuracies(\"training and validation accuracy\")\n","trainer.plot_confusion_matrix(test_dataloader, 'confusion matrix')\n","y_pred, y_eval, loss, accuracy = trainer.eval(test_dataloader)\n","print(\"accuracy: \", accuracy * 100)"],"metadata":{"id":"UmlH2L1VABHe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.6. GRU with Using Mean Value of All Hidden Layers"],"metadata":{"id":"bYzOt37qABHi"}},{"cell_type":"code","source":["%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss\n","loss = torch.nn.CrossEntropyLoss()\n","model = GRU(\n","    input_size=input_size, \n","    time_sequence=time_sequence,\n","    hidden_size=hidden_size, \n","    num_layers=num_layers, \n","    output_dim=output_dim,\n","    use_mean=True\n","    ).to(device)\n","loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","print(model)\n","trainer = RNNFbankTrainer(\n","    model=model, \n","    optimizer=optimizer, \n","    loss=loss, \n","    train_dataloader=train_dataloader, \n","    validation_dataloader=validation_dataloader, \n","    num_epochs=num_epochs)\n","trainer.train()\n","trainer.plot_loss(\"training and validation loss\")\n","trainer.plot_accuracies(\"training and validation accuracy\")\n","trainer.plot_confusion_matrix(test_dataloader, 'confusion matrix')\n","y_pred, y_eval, loss, accuracy = trainer.eval(test_dataloader)\n","print(\"accuracy: \", accuracy * 100)"],"metadata":{"id":"voow8NHVABHj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Convolutional Neural Network\n","After examining the RNN to train a classifier for our project, we have decided to use CNN to compare our result with. We have trained three different models for our CNN including VanillaConv1d, VanillaConv1d, Conv2d, which each of them becomes more complex in terms of architecture. Also, we tried to keep the architecture close to RNN which makes the results compareable. As of this reason, we used learning rate equal to 0.001 for all CNN models.\n"],"metadata":{"id":"plGAkwrEJiyX"}},{"cell_type":"code","source":["lr = 0.001"],"metadata":{"id":"uXkwMuli2Npg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.1. VanillaConv1d "],"metadata":{"id":"wi3Wq9qZWMTG"}},{"cell_type":"code","source":["%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss\n","model = VanillaConv1d().to(device)\n","loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","print(model)\n","trainer = CNNFbankTrainer(\n","    model=model, \n","    optimizer=optimizer, \n","    loss=loss, \n","    train_dataloader=train_dataloader, \n","    validation_dataloader=validation_dataloader, \n","    num_epochs=num_epochs)\n","trainer.train()\n","trainer.plot_loss(\"training and validation loss\")\n","trainer.plot_accuracies(\"training and validation accuracy\")\n","trainer.plot_confusion_matrix(test_dataloader, 'confusion matrix')\n","y_pred, y_eval, loss, accuracy = trainer.eval(test_dataloader)\n","print(\"accuracy: \", accuracy * 100)"],"metadata":{"id":"0x1XmqMe2Tpp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.2. Conv1d"],"metadata":{"id":"rd9sNmxNWXYX"}},{"cell_type":"code","source":["%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss\n","loss = torch.nn.CrossEntropyLoss()\n","model = Conv1d().to(device)\n","print(model)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","trainer = CNNFbankTrainer(\n","    model=model, \n","    optimizer=optimizer, \n","    loss=loss, \n","    train_dataloader=train_dataloader, \n","    validation_dataloader=validation_dataloader, \n","    num_epochs=num_epochs)\n","trainer.train()\n","trainer.plot_loss(\"training and validation loss\")\n","trainer.plot_accuracies(\"training and validation accuracy\")\n","trainer.plot_confusion_matrix(test_dataloader, 'confusion matrix')\n","y_pred, y_eval, loss, accuracy = trainer.eval(test_dataloader)\n","print(\"accuracy: \", accuracy * 100)"],"metadata":{"id":"O9Qmc5J35Xle"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.3. VanillaConv2d"],"metadata":{"id":"L8A2Ff1WWbpT"}},{"cell_type":"code","source":["%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss\n","loss = torch.nn.CrossEntropyLoss()\n","model = VanillaConv2d().to(device)\n","print(model)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","trainer = CNNFbankTrainer(\n","    model=model, \n","    optimizer=optimizer, \n","    loss=loss, \n","    train_dataloader=train_dataloader, \n","    validation_dataloader=validation_dataloader, \n","    num_epochs=num_epochs)\n","trainer.train()\n","trainer.plot_loss(\"training and validation loss\")\n","trainer.plot_accuracies(\"training and validation accuracy\")\n","trainer.plot_confusion_matrix(test_dataloader, 'confusion matrix')\n","y_pred, y_eval, loss, accuracy = trainer.eval(test_dataloader)\n","print(\"accuracy: \", accuracy * 100)"],"metadata":{"id":"6ZMNC18R9LEy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Free Memory :)\n","%reset_selective -f model\n","%reset_selective -f trainer\n","%reset_selective -f optimizer\n","%reset_selective -f loss"],"metadata":{"id":"FB2JXynOCfBY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Multiple Model Training\n","In this part, we have written a class which is responsible to train some of the `sklearn` models. So, we can pass a dictionary of various models with different parameters to a the class and it trains them all one by one. This was helpful for hyperparameter search.\n","\n","\n"],"metadata":{"id":"CCE__U8NAnXK"}},{"cell_type":"markdown","source":["## 4.1. Dataset as Numpy\n","Since `Sklearn` only works with Numpy, we need to redefine the features as Numpy arrays instead of torch Tensors. Also, in the previous parts (NN), the feature extraction was done during loading the dataset in the DataLoader to save more memory. Here we need to convert the Numpy arrays to FBank Featurs and then use them to train models."],"metadata":{"id":"5OwSjAbNaOvy"}},{"cell_type":"code","source":["X,y = train_preprcessor.as_shuffled_numpy()\n","X_test, y_test = test_preprcessor.as_shuffled_numpy()\n","\n","feature_maker = Feature()\n","X_features = feature_maker.numpy_fbank_features(X).reshape(-1,702*40)\n","X_test_features = feature_maker.numpy_fbank_features(X_test).reshape(-1,702*40)"],"metadata":{"id":"CbrxbcfKAyFu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2. Defining Models and Parameters\n","\n","The following dictionary shows how easy we can create various models based on their name and their paramters. It is possible to have i.e. multiple SVMs with different hyperparameters at the same time. "],"metadata":{"id":"XwoLL2XJCkvn"}},{"cell_type":"code","source":["models = {\n","    \"mlp\": {\n","        \"name\": \"mlp\",\n","        \"parameters\": {\n","            \"hidden_layer_sizes\": (128,128,128,128,128),\n","            \"solver\": \"adam\",\n","            \"max_iter\": 100,\n","            \"early_stopping\": True,\n","         }\n","    },\n","    \"svm_ovo\": {\n","          \"name\": \"svm\",\n","          \"parameters\": {\n","            \"decision_function_shape\":\"ovo\"\n","          }\n","    },\n","    \"svm_ovr\": {\n","          \"name\": \"svm\",\n","          \"parameters\": {\n","            \"decision_function_shape\":\"ovr\"\n","          }\n","    },\n","    \"decision_tree\": {\n","          \"name\": \"decision_tree\",\n","          \"parameters\": {\n","          }\n","    },\n","    \"random_forest\": {\n","          \"name\": \"random_forest\",\n","          \"parameters\": {\n","          }\n","    },\n","\n","}"],"metadata":{"id":"BjSiOs0oAvhp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training the Defined Models\n","\n","We can pass the models as a parameter to the defined class and then we can set three more variables. We can ask to use PCA with a specific number of components or we can have MinMaxScaler normalization if it is needed. So, it helps us to investigate the effect of both in addition to hyperparamter search."],"metadata":{"id":"v4Yfbj8BCwp2"}},{"cell_type":"code","source":["trainer = SklearnTrainer(models=models, use_norm=True, use_pca=True, pca_size=200)\n","trainer.train(X_features, y)"],"metadata":{"id":"vVKwcNv6Co7G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluating the Models\n","\n","In the last step, we can evaluate the model and retrieve the information for each model such as accuracy data."],"metadata":{"id":"Q_yr5_O0C40M"}},{"cell_type":"code","source":["evaluations = trainer.eval(X_test_features, y_test)"],"metadata":{"id":"yTlnc0LeC3qM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Also, we can generate the classification report for all models at the same time and compare them. Don't forget to evaluate first and then pull these information."],"metadata":{"id":"WOxavcfRbVyK"}},{"cell_type":"code","source":["trainer.classification_report();"],"metadata":{"id":"rbhoarDVDCXK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Moreover, we will have access to confusion matrix for all models upon request."],"metadata":{"id":"PTMDthmcbcbs"}},{"cell_type":"code","source":["trainer.plot_confusion_matrix()"],"metadata":{"id":"k9zGKSekDK7Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. KMeans Clustering\n","We have used KMeans as part of our project to see if we can define clusters properly with in the samples and we check to see if we can assign each cluster to a set of genres. More details are available on the report.\n"],"metadata":{"id":"aQDNqyMSDUw9"}},{"cell_type":"code","source":["trained_genres = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","model = KmeansTrainer(trained_genres)\n","model.train(X_features, y)\n","y_pred_features = model.eval(X_test_features, y_test)\n","model.accuracy_score(X_test_features, y_test)\n","model.plot_adjusted_matrix(X_test_features, y_test)"],"metadata":{"id":"w7YQkR0QDPQ_"},"execution_count":null,"outputs":[]}]}