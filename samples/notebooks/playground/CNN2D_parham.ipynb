{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21997,"status":"ok","timestamp":1649162694878,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"4LGl0-Lrnw_5","outputId":"db386ce1-5b75-4071-e8d5-64f04f0e30c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6509,"status":"ok","timestamp":1649162701380,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"8cxtLBk7L9JV"},"outputs":[],"source":["%%capture\n","%cd drive/MyDrive/genrecog/\n","%pip install speechbrain"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":10325,"status":"ok","timestamp":1649162711695,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"COt64u6Ovpa2"},"outputs":[],"source":["from genrecog.preprocess.preprocessor import Preprocessor\n","from genrecog.nnet.CNN import Conv1d\n","from genrecog.tools.trainer import FbankTrainer\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","from importlib import reload\n","import matplotlib.pyplot as plt\n","import speechbrain as sb"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1649162711697,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"fxasa4Yzvq0e"},"outputs":[],"source":["# Load dataset\n","\n","train_preprcessor = Preprocessor('dataset/npz_files/train.npz')\n","test_preprcessor = Preprocessor('dataset/npz_files/test.npz')\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":43588,"status":"ok","timestamp":1649162755278,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"wkJQ7G1EvsZ4"},"outputs":[],"source":["X, y = train_preprcessor.as_shuffled_torch()\n","X_test, y_test = test_preprcessor.as_shuffled_torch()\n","\n","dataset = TensorDataset(X.to(device), y.to(device))\n","validation_dataset, train_dataset = torch.utils.data.random_split(dataset, (400, 3200))\n","test_dataset = TensorDataset(X_test.to(device), y_test.to(device))\n","\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=400)\n","validation_dataloader = DataLoader(validation_dataset, shuffle=True, batch_size=400)\n","test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=400)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1649162755280,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"c9yR0Yflvt0a"},"outputs":[],"source":["# model = Conv1d(40)\n","# optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n","# loss = torch.nn.CrossEntropyLoss()\n","\n","# if torch.cuda.is_available():\n","#   model = model.cuda()\n","#   loss = loss.cuda()\n","  \n","# model"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1649162755282,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"R0BbC2Frq8l-"},"outputs":[],"source":["# class Conv1d(torch.nn.Module):\n","#     def __init__(\n","#             self,\n","#             in_channels=40\n","#     ):\n","#         super().__init__()\n","#         self.filter_num = 128\n","#         self.filter_size = 32\n","#         self.in_channels = in_channels\n","#         self.batch_norm = torch.nn.BatchNorm1d(40)\n","#         self.input_layer = self.conv1d_block(40, 128, 8, 8)\n","#         self.hidden_layer = self.conv1d_block(128, 128, 8, 8)\n","\n","#         self.out_linear = torch.nn.Linear(in_features=384, out_features=10)\n","\n","#     def conv1d_block(self, in_channels, out_channels, kernel_size, padding):\n","#         return nn.Sequential(\n","#             torch.nn.Conv1d(in_channels=in_channels,\n","#                             out_channels=out_channels,\n","#                             kernel_size=kernel_size,\n","#                             padding=padding\n","#                             ),\n","#             torch.nn.BatchNorm1d(out_channels),\n","#             torch.nn.LeakyReLU(),\n","#             torch.nn.MaxPool1d(kernel_size=4),\n","#         )\n","\n","#     def forward(self, x):\n","#         z = x.transpose(-1,1)\n","#         z = self.batch_norm(z)\n","#         z = self.input_layer(z)\n","#         z = self.hidden_layer(z)\n","#         z = self.hidden_layer(z)\n","#         z = self.hidden_layer(z)\n","#         z = self.hidden_layer(z)\n","#         z = self.hidden_layer(z)\n","#         z = z.view(x.size(0), -1)\n","#         z = self.out_linear(z)\n","#         return z"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1649162755283,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"owvLLCR-UQtL"},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","\n","\n","# class Conv1d(nn.Module):\n","#     def __init__(\n","#             self,\n","#             in_channels=40\n","#     ):\n","#         super().__init__()\n","#         self.filter_num = 128\n","#         self.filter_size = 32\n","#         self.in_channels = in_channels\n","#         self.input_layer = self.conv1d_block(40, 128, 32, 16)\n","#         self.hidden_layer_1 = self.conv1d_block(128, 256, 32, 16)\n","#         self.hidden_layer_2 = self.conv1d_block(256, 512, 32, 16)\n","#         self.hidden_layer_3 = self.conv1d_block(512, 1024, 32, 16)\n","#         self.hidden_layer_4 = self.conv1d_block(1024, 2048, 32, 16)\n","#         self.out_linear_1 = torch.nn.Linear(in_features=2048, out_features=1024)\n","#         self.out_linear_2 = torch.nn.Linear(in_features=1024, out_features=512)\n","#         self.out_linear_3 = torch.nn.Linear(in_features=512, out_features=256)\n","#         self.out_linear_4 = torch.nn.Linear(in_features=256, out_features=128)\n","#         self.out_linear_5 = torch.nn.Linear(in_features=128, out_features=10)\n","\n","#     def conv1d_block(self, in_channels, out_channels, kernel_size, padding):\n","#         return torch.nn.Sequential(\n","#             torch.nn.Conv1d(in_channels=in_channels,\n","#                             out_channels=out_channels,\n","#                             kernel_size=kernel_size,\n","#                             padding=padding\n","#                             ),\n","#             torch.nn.BatchNorm1d(out_channels),\n","#             torch.nn.LeakyReLU(),\n","#             torch.nn.MaxPool1d(kernel_size=4),\n","#         )\n","\n","#     def forward(self, x):\n","#         x = self.input_layer(x)\n","#         x = self.hidden_layer_1(x)\n","#         x = self.hidden_layer_2(x)\n","#         x = self.hidden_layer_3(x)\n","#         x = self.hidden_layer_4(x)\n","#         x = x.view(x.size(0), -1)\n","#         x = self.out_linear_1(x)\n","#         x = self.out_linear_2(x)\n","#         x = self.out_linear_3(x)\n","#         x = self.out_linear_4(x)\n","#         x = self.out_linear_5(x)\n","#         return x"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1649162755284,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"LHWcNnqMwDo-"},"outputs":[],"source":["# lr = 0.001\n","# num_epoch = 10\n","# hidden_size = 128\n","# num_layers = 10\n","\n","# # rnn = CNN2D().to(device)\n","# conv1d = Conv1d().to(device)\n","# print(conv1d)\n","# loss = torch.nn.CrossEntropyLoss()\n","# optimizer = torch.optim.Adam(conv1d.parameters(), lr=lr)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1649162755285,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"IFp3Y4vYZOas"},"outputs":[],"source":["# from genrecog.tools.trainer import CNNFbankTrainer\n","# trainer = CNNFbankTrainer(conv1d, optimizer, loss, train_dataloader, validation_dataloader, num_epochs=100)\n","# trainer.train()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1649162755286,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"xpdRX7_dbMNs"},"outputs":[],"source":["# trainer.eval(test_dataloader)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1649162755288,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"p-lLAbxJcykV"},"outputs":[],"source":["# trainer.plot_accuracies('acc')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1649162755289,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"x13ECz80c-aq"},"outputs":[],"source":["# trainer.plot_confusion_matrix(test_dataloader)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1649162755290,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"sGngl7rsvym_"},"outputs":[],"source":["# # trainer = FbankTrainer(rnn, optimizer, loss, train_dataloader, validation_dataloader, num_epochs=100)\n","# # trainer.train()\n","# from genrecog.preprocess.feature import Feature\n","# import numpy as np\n","\n","\n","\n","# feature_maker = Feature()\n","# for epoch in range(500):\n","#     conv1d.train()\n","#     epoch_losses = []\n","#     for X_train, y_train in train_dataloader:\n","#         conv1d.zero_grad()\n","#         X_features = feature_maker.torch_fbank_features(X_train)\n","#         X_features = torch.nn.functional.normalize(X_features, dim=1)\n","#         # plt.imshow(X_features.cpu()[0])\n","#         # y_hat = rnn(X_features.unsqueeze(1))\n","#         y_hat = conv1d(X_features.transpose(-1,1))\n","#         # print(y_hat.argmax(dim=1))\n","#         l = loss(y_hat, y_train)\n","#         l.backward()\n","#         optimizer.step()\n","#         epoch_losses.append(l.item())\n","#         # print(\"Epoch %2d final minibatch had loss %.4f\" % (epoch, l.item()))\n","#     print(epoch, np.average(epoch_losses))\n","    \n","#     # train_losses.append(sum(epoch_losses) / len(epoch_losses))\n","#     # y_pred, y_eval, validation_loss = self.eval()\n","#     # print(\"Epoch %2d final minibatch had test loss %.4f\" % (epoch, validation_loss))\n","#     # self.validation_losses.append(validation_loss)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1649162755290,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"s7j2HVwGBQsK"},"outputs":[],"source":["# def tryy(conv1d):\n","#   conv1d.eval()\n","#   X_test, y_test = next(iter(test_dataloader))\n","#   # print(X.shape)\n","#   X_features = feature_maker.torch_fbank_features(X_test)\n","#   # X_features = torch.nn.functional.normalize(X_features, dim=0)\n","#   # rnn(X_features).softmax(dim=0)\n","#   y_pred = conv1d(X_features.transpose(1,2))\n","#   # print(y_pred[0])\n","#   y_pred_1 = torch.argmax(y_pred, dim=1)\n","#   # y_pred_1\n","#   return y_pred_1"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1649162755291,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"tnqRHnlTNq3C"},"outputs":[],"source":["# from sklearn.metrics import classification_report\n","# # y_pred, y_eval, validation_loss, validation_accuracy = self.eval(eval_loader)\n","# conv1d.eval()\n","# X_test, y_test = next(iter(train_dataloader))\n","# # print(X.shape)\n","# X_features = feature_maker.torch_fbank_features(X_test)\n","# # X_features = torch.nn.functional.normalize(X_features, dim=0)\n","# # rnn(X_features).softmax(dim=0)\n","# y_pred = conv1d(X_features.transpose(1,2))\n","# # print(y_pred[0])\n","# y_pred_1 = torch.argmax(y_pred, dim=1)\n","# genres = ['country', 'reggae', 'metal', 'pop', 'classical', 'disco', 'hiphop', 'blues', 'jazz', 'rock']\n","# print(classification_report(y_test.cpu(), y_pred_1.cpu(), target_names=genres))"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1649162755291,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"IHk1OIOIOTsX"},"outputs":[],"source":["# import seaborn as sn\n","# import pandas as pd\n","# import matplotlib.pyplot as plt\n","# from sklearn.metrics import confusion_matrix\n","# from sklearn.metrics import classification_report\n","# import pickle\n","\n","# # y_pred, y_eval, validation_loss, validation_accuracy = self.eval(eval_loader)\n","# array = confusion_matrix(y_test.cpu(), y_pred_1.cpu(), normalize='true')*100\n","# genres = ['country', 'reggae', 'metal', 'pop', 'classical', 'disco', 'hiphop', 'blues', 'jazz', 'rock']\n","# df_cm = pd.DataFrame(array, index = genres, columns = genres)\n","# plt.figure(figsize = (10,7))\n","# sn.heatmap(df_cm, annot=True, cmap=\"YlGnBu\")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1649162755292,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"FYjEfD_5vvdl"},"outputs":[],"source":["# import torch.nn as nn\n","\n","# class CNN2D(torch.nn.Module):\n","#   def __init__(self):\n","#     super(CNN2D, self).__init__()\n","\n","#     self.conv1 = nn.Sequential(         \n","#             nn.Conv2d(\n","#                 in_channels=1,              \n","#                 out_channels=128,            \n","#                 kernel_size=(32,10),              \n","#                 # stride=1,                   \n","#                 # padding=16,                  \n","#             ),                              \n","#             nn.ReLU(),      \n","#             nn.BatchNorm2d(num_features=128),                \n","#             # nn.MaxPool2d(kernel_size=4),    \n","#         )\n","#     self.conv2 = nn.Sequential(         \n","#         nn.Conv2d(128, 64, 4, 1, 2),     \n","#         nn.LeakyReLU(),                      \n","#         nn.MaxPool2d(4),                \n","#     )        # fully connected layer, output 10 classes\n","#     self.out = nn.Linear(2662528, 10)\n","\n","#   def forward(self, x):\n","#     x = self.conv1(x)\n","#     # x = self.conv1(x)\n","#     # x = self.conv2(x)        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n","#     x = x.view(x.size(0), -1)       \n","#     output = self.out(x)\n","#     return output\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1649162755292,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"c0TR2xIItkR1"},"outputs":[],"source":["# from sklearn.metrics import accuracy_score\n","# accuracy_score(y_pred_1.cpu(), y.cpu())"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1649162755293,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"d3zSaQLywPic"},"outputs":[],"source":["# import torchlibrosa as tl\n","# X, y = next(iter(test_dataloader))\n","\n","\n","# batch_size = 16\n","# sample_rate = 22050\n","# win_length = 702\n","# hop_length = 512\n","# n_mels = 128\n","\n","# spectrogram_extractor = tl.Spectrogram(n_fft=win_length, hop_length=hop_length)\n","# sp = spectrogram_extractor.forward(X[:10].cpu())   # (batch_size, 1, time_steps, freq_bins)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":788},"executionInfo":{"elapsed":20,"status":"error","timestamp":1649162755511,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"ePjAMnNgxGxu"},"outputs":[],"source":["# sp.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1649162755507,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"KO7uSzrRxyfQ"},"outputs":[],"source":["# # sb.nnet.RNN.RNN\n","# net = sb.nnet.RNN.RNN(hidden_size=128, input_shape=X_features.shape)\n","# out, _ = net(X_features.cpu())\n","# # out[:,-1,:]\n","# linear = torch.nn.Linear(128,10)\n","# out = linear(out[:,-1,:])\n","# print(out.shape)\n","# out.argmax(dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1649162755508,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"7afmMtzosYiE"},"outputs":[],"source":["# import torch\n","# import torchlibrosa as tl\n","\n","\n","# batch_size = 16\n","# sample_rate = 22050\n","# win_length = 2048\n","# hop_length = 512\n","# n_mels = 40\n","\n","# spectrogram_extractor = tl.Spectrogram(n_fft=win_length, hop_length=hop_length)\n","# sp = spectrogram_extractor.forward(X_train.cpu())\n","# logmel_extractor = tl.LogmelFilterBank(sr=sample_rate, n_fft=win_length, n_mels=n_mels)\n","# logmel = logmel_extractor.forward(sp) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1649162755509,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"KfGcFpxA6KI-"},"outputs":[],"source":["# logmel.squeeze(1).shape\n","# plt.imshow(logmel.squeeze(1).cpu().transpose(1,2)[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1649162755509,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"kGtwsjtg7peC"},"outputs":[],"source":["# rnn2 = RNN(input_size=40, hidden_size=hidden_size, num_layers=num_layers).to(device)\n","# from genrecog.preprocess.feature import Feature\n","# import numpy as np\n","\n","\n","# spectrogram_extractor = tl.Spectrogram(n_fft=win_length, hop_length=hop_length).cuda()\n","# logmel_extractor = tl.LogmelFilterBank(sr=sample_rate, n_fft=win_length, n_mels=n_mels).cuda()\n","\n","# feature_maker = Feature()\n","# for epoch in range(500):\n","#     rnn2.train()\n","#     epoch_losses = []\n","#     for X_train, y_train in train_dataloader:\n","#         rnn.zero_grad()\n","#         sp = spectrogram_extractor.forward(X_train)\n","#         logmel = logmel_extractor.forward(sp).squeeze(1)\n","#         y_hat = rnn2(logmel)\n","#         # print(y_hat.argmax(dim=1))\n","#         l = loss(y_hat, y_train)\n","#         l.backward()\n","#         optimizer.step()\n","#         epoch_losses.append(l.item())\n","#         # print(\"Epoch %2d final minibatch had loss %.4f\" % (epoch, l.item()))\n","#     print(epoch, np.average(epoch_losses))\n","    "]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1649163765052,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"Shvkxq0lgdwp"},"outputs":[],"source":["import torch.nn as nn\n","\n","class VanillaConv2d(torch.nn.Module):\n","  def __init__(self):\n","    super(VanillaConv2d, self).__init__()\n","\n","    self.batch_norm = nn.BatchNorm2d(1)\n","    self.input_conv = nn.Sequential(         \n","            nn.Conv2d(\n","                in_channels=1,              \n","                out_channels=128,            \n","                kernel_size=(8,8),              \n","                stride=1,                   \n","                # padding=16,                  \n","            ),                              \n","            nn.BatchNorm2d(num_features=128),                \n","            nn.LeakyReLU(),      \n","            # nn.MaxPool2d(kernel_size=4),    \n","        )\n","    self.hidden_conv = nn.Sequential(         \n","        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(4,8), stride=1), \n","        nn.BatchNorm2d(num_features=128),      \n","        nn.LeakyReLU(),                      \n","        nn.MaxPool2d(4),                \n","    )\n","    self.out = nn.Linear(2662528, 10)\n","\n","  def forward(self, x):\n","    x = x.unsqueeze(1)\n","    x = self.batch_norm(x)\n","    print(x.shape)\n","    x = self.input_conv(x)\n","    x = self.hidden_conv(x)\n","    x = x.view(x.size(0), -1)       \n","    output = self.out(x)\n","    return output"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1649163767398,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"_uDvQzQew5kX"},"outputs":[{"data":{"text/plain":["VanillaConv2d(\n","  (batch_norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (input_conv): Sequential(\n","    (0): Conv2d(1, 128, kernel_size=(8, 8), stride=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.01)\n","  )\n","  (hidden_conv): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(4, 8), stride=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.01)\n","    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (out): Linear(in_features=2662528, out_features=10, bias=True)\n",")"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["lr = 0.001\n","model = VanillaConv2d().to(device)\n","loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","model"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"elapsed":658,"status":"error","timestamp":1649163770121,"user":{"displayName":"Parham Ashraf","userId":"12851010305026686994"},"user_tz":240},"id":"puNJREmTv3Sz"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([400, 1, 702, 40])\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-28-f42d6fd7c6d3\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgenrecog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCNNFbankTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNFbankTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/.shortcut-targets-by-id/170MSEq2QnQbtKqmcDX4AScOEdKvRZe-R/genrecog/genrecog/tools/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mX_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_maker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_fbank_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 115\u001b[0;31m                 \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-26-c9291d43c491\u003e\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 32\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 738\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1475\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.38 GiB (GPU 0; 14.76 GiB total capacity; 11.47 GiB already allocated; 1.81 GiB free; 11.63 GiB reserved in total by PyTorch) If reserved memory is \u003e\u003e allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["from genrecog.tools.trainer import CNNFbankTrainer\n","trainer = CNNFbankTrainer(model, optimizer, loss, train_dataloader, validation_dataloader, num_epochs=100)\n","trainer.train()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CNN2D_parham.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}